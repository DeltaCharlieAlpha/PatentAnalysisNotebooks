{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patent Analysis in Python\n",
    "### Sample using a training dataset directed at BlockChain patents and predicting relevance in the IBM portofolio\n",
    "David Andrews\n",
    "Legal Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample connects to Google BigQuery to retrieve patent data.  You need to do some setup in Google's cloud dev platform if you are not already using Google BigQuery.  You can reference one of the many great tutorials on setting up Google BigQuery for the first time to get the libraries installed, credentials cached, and project ID setup.\n",
    "\n",
    "#### Caveat\n",
    "This sample uses a very dumb training set.  The 'positive' samples, or samples labeled as being related to Block Chain, were gathered by doing a simple keyword search on Google Patents.  The results were not reviewed by hand and there was no effort to be inclusive.  As a result, the final results are interesting, but not demonstrative of what a fully-trained ML model can do when predicting results.  The 'negative' samples were created by doing a random search for patents, which means they are probably not blockchain related.  Immediately better results could be obtained by providing negative samples that weed out things like financial transactions patents that don't use block chain or similar technology. If you improve the training set and I would appreciate the opportunity to improve these results by including your updated training data.  You can email me at david@analytics.legal and I can re-publish the training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#import lots of stuff\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication_Number</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-2015310424-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US-2015120567-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US-2015170112-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US-2015379510-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US-2015287026-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US-2015356555-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US-2015332256-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>US-2015371224-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US-2015332283-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>US-2015206106-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>US-2015356524-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US-2016321654-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>US-2017011460-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>US-9397985-B1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>US-2016261411-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>US-2015294308-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>US-2015324764-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>US-2016342977-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>US-2016300234-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>US-2017177855-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>US-9298806-B1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>US-2017178237-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>US-2016012424-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>US-2015244690-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>US-2017046651-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>US-2017132630-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>US-2015278820-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>US-2016218879-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>US-2015227890-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>US-2016350749-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>US-8489331-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>US-8494215-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>US-8498100-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>US-8521513-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>US-8538960-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>US-8539384-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>US-8548494-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>US-8560959-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>US-8576276-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>US-8578486-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>US-8582206-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>US-8584094-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>US-8594467-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>US-8612550-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>US-8639625-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>US-8670183-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>US-8675067-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>US-8687023-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>US-8713535-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>US-8719603-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>US-8752963-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>US-8793304-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>US-8814691-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>US-8830270-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>US-8873227-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>US-8896594-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>US-8903430-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>US-8964298-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>US-9128281-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>US-9129295-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1148 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Publication_Number  Label\n",
       "0      US-2015310424-A1      1\n",
       "1      US-2015120567-A1      1\n",
       "2      US-2015170112-A1      1\n",
       "3      US-2015379510-A1      1\n",
       "4      US-2015287026-A1      1\n",
       "5      US-2015356555-A1      1\n",
       "6      US-2015332256-A1      1\n",
       "7      US-2015371224-A1      1\n",
       "8      US-2015332283-A1      1\n",
       "9      US-2015206106-A1      1\n",
       "10     US-2015356524-A1      1\n",
       "11     US-2016321654-A1      1\n",
       "12     US-2017011460-A1      1\n",
       "13        US-9397985-B1      1\n",
       "14     US-2016261411-A1      1\n",
       "15     US-2015294308-A1      1\n",
       "16     US-2015324764-A1      1\n",
       "17     US-2016342977-A1      1\n",
       "18     US-2016300234-A1      1\n",
       "19     US-2017177855-A1      1\n",
       "20        US-9298806-B1      1\n",
       "21     US-2017178237-A1      1\n",
       "22     US-2016012424-A1      1\n",
       "23     US-2015244690-A1      1\n",
       "24     US-2017046651-A1      1\n",
       "25     US-2017132630-A1      1\n",
       "26     US-2015278820-A1      1\n",
       "27     US-2016218879-A1      1\n",
       "28     US-2015227890-A1      1\n",
       "29     US-2016350749-A1      1\n",
       "...                 ...    ...\n",
       "1120      US-8489331-B2      0\n",
       "1121      US-8494215-B2      0\n",
       "1122      US-8498100-B1      0\n",
       "1123      US-8521513-B2      0\n",
       "1124      US-8538960-B2      0\n",
       "1125      US-8539384-B2      0\n",
       "1126      US-8548494-B2      0\n",
       "1127      US-8560959-B2      0\n",
       "1128      US-8576276-B2      0\n",
       "1129      US-8578486-B2      0\n",
       "1130      US-8582206-B2      0\n",
       "1131      US-8584094-B2      0\n",
       "1132      US-8594467-B2      0\n",
       "1133      US-8612550-B2      0\n",
       "1134      US-8639625-B1      0\n",
       "1135      US-8670183-B2      0\n",
       "1136      US-8675067-B2      0\n",
       "1137      US-8687023-B2      0\n",
       "1138      US-8713535-B2      0\n",
       "1139      US-8719603-B2      0\n",
       "1140      US-8752963-B2      0\n",
       "1141      US-8793304-B2      0\n",
       "1142      US-8814691-B2      0\n",
       "1143      US-8830270-B2      0\n",
       "1144      US-8873227-B2      0\n",
       "1145      US-8896594-B2      0\n",
       "1146      US-8903430-B2      0\n",
       "1147      US-8964298-B2      0\n",
       "1148      US-9128281-B2      0\n",
       "1149      US-9129295-B2      0\n",
       "\n",
       "[1148 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load in the samples of patents we want to find\n",
    "#these files are just flat lists of patent numbers.  Positives are examples of block chain patents and negatives \n",
    "#are random non-blockchain patents.  Stored on public google sheets share.\n",
    "negative_url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vTwNjPYeJV6l0lOTjMnI65rE4i_Prtc4Gnku3HupqBzuZ5v9wzhYWAA26AivTkFPw_AbwGuiuqoj_lq/pub?output=csv\"\n",
    "positive_url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSD-tiMAUTosTzEz9jiqK0JMhFLr3s_Jeb7J5Ry39NoIaEHE-Iqr1M7etvDJBTZA0ilgmUjb6KU-TCs/pub?output=csv\"\n",
    "df_positive_samples = pd.read_csv(positive_url)\n",
    "#load samples of patents that are counter-examples\n",
    "df_negative_samples = pd.read_csv(negative_url)\n",
    "\n",
    "#Create Label column to hold the labels\n",
    "#label blockchain patents 1\n",
    "df_positive_samples['Label'] = 1\n",
    "#label non-blockahin patents 0\n",
    "df_negative_samples['Label'] = 0\n",
    "\n",
    "#combine labeled data into a training set\n",
    "df_training_set = pd.concat([df_positive_samples, df_negative_samples], ignore_index=True)\n",
    "\n",
    "#change the format of the publication number from US1234567B2 to US-1234567-B2 to match the format in the database\n",
    "df_training_set['Publication_Number'] = df_training_set['Publication_Number'].str.replace(r\"(\\D*)(\\d*)(\\D\\d?)\", \"\\\\1-\\\\2-\\\\3\")\n",
    "#input data has some funky pub numbers for applications with an extra 0 after the year portion of the pub number.\n",
    "#need to strip it so it matches the format in Google BigQuery\n",
    "df_training_set['Publication_Number'] = df_training_set['Publication_Number'].str.replace(r\"(\\D*-)(\\d{4})0(\\d{6})(-A1)\",\n",
    "                                                                                         \"\\\\1\\\\2\\\\3\\\\4\")\n",
    "\n",
    "#unpacking the above REGEXP a little:\n",
    "# (\\D*) = grab all the non-digits at the front e.g. US\n",
    "# (\\d*) = grab all the digits, e.g. 1234567\n",
    "# (\\D\\d?) = grab a trailing non-digit optionally followed by a digit e.g. A1 or B2 or A \n",
    "\n",
    "\n",
    "df_training_set.drop_duplicates(['Publication_Number'], inplace=True)\n",
    "#show the training set to see what it looks like.  Make sure it imported correctly.\n",
    "display(df_training_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note there are some non-US patents in the Negatives training example.  Our SQL join below will weed those out, so you may notice that the row count decreases from this query to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to  Google BigQuery and upload patent numbers & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Streaming Insert is 100.0% Complete\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load the dataset to Google BigQuery so we can join against the public patents data\n",
    "\n",
    "#If you don't want to try to get GBQ working, you can download the results of this step here:\n",
    "#combined_url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSfXq_QpXjL3eskKnbezF33GgcBM7O1KB-TAPrfcZk1cYXdQWQWU5X_oAICJr5ipXearXbJ19_Rp4PY/pub?output=csv\"\n",
    "#df_training_set_finished = pd.read_csv(\"combined_url\")\n",
    "#then skip to Prepare Machine Learning Pipeline below\n",
    "\n",
    "\n",
    "# Variables to be used to access GBQ, replace with your project id, and optionally change the table and\n",
    "# and dataset name.\n",
    "PROJECT_ID = 'patenttest-182300' #change this to your project ID\n",
    "DEST_DATASET = 'my_new_dataset'\n",
    "samples_table = 'training_patents'\n",
    "\n",
    "# Create a python client we can use for executing table creation queries\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "# Create an HTTP client for additional functionality.\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "http_client = discovery.build('bigquery', 'v2', credentials=credentials)\n",
    "\n",
    "#attach to the dataset\n",
    "dataset = client.dataset(DEST_DATASET)\n",
    "\n",
    "#create the table by having Pandas push up the dataframe as a table\n",
    "full_table_path = '{}.{}'.format(DEST_DATASET, samples_table)\n",
    "df_training_set.to_gbq(destination_table=full_table_path,\n",
    "          project_id=PROJECT_ID,\n",
    "          if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query BigQuery to get training text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting query... ok.\n",
      "Job ID: job_Ic0ZpX_SFT1RjExOrNCJOgc8D63N\n",
      "Query running...\n",
      "Query done.\n",
      "Processed: 155.0 GB\n",
      "Standard price: $0.76 USD\n",
      "\n",
      "Retrieving results...\n",
      "Got 1101 rows.\n",
      "\n",
      "Total time taken 6.62 s.\n",
      "Finished at 2018-01-15 16:18:33.\n",
      "Shape: (1101, 3)\n"
     ]
    }
   ],
   "source": [
    "#create our query string.  The query joins the BigQuery patent data using our training set\n",
    "# publication number.  Because we formatted in Python to match the BigQuery format, we can just use traing equality\n",
    "# in the \"on\" clause of the join.\n",
    "# The concat combines the data fields we are interested in.  For our training data, we are going to use\n",
    "# the title, abstract, claims, and CPC codes combined into one text block to feed into the machine learning code.\n",
    "\n",
    "query = \"\"\"\n",
    "select pubs.publication_number, Label,\n",
    "  CONCAT(\n",
    "    IFNULL(\n",
    "     (SELECT text from UNNEST(pubs.title_localized)), \" \"), \" \",\n",
    "    IFNULL(\n",
    "     (SELECT text from UNNEST(pubs.abstract_localized)), \" \"), \" \",\n",
    "    IFNULL(  \n",
    "     (SELECT text from UNNEST(pubs.claims_localized)), \" \"), \" \",\n",
    "    IFNULL(\n",
    "     ARRAY_TO_STRING( ARRAY(SELECT code from UNNEST(pubs.cpc)), \" \"), \" \" ), \" \",\n",
    "    IFNULL(\n",
    "     ARRAY_TO_STRING( ARRAY(SELECT REGEXP_REPLACE( code, \"/.*\", \"\") from UNNEST(pubs.cpc)), \" \"), \" \")) as text\n",
    "from\n",
    "  `patents-public-data.patents.publications` as pubs, UNNEST(title_localized) as title\n",
    "  JOIN `\"\"\" + full_table_path + \"\"\"` as input\n",
    "  on pubs.publication_number = input.Publication_Number  \n",
    "where (SELECT language from UNNEST(pubs.title_localized) LIMIT 1) = 'en' and\n",
    "(SELECT language from UNNEST(pubs.abstract_localized) LIMIT 1) = 'en' and\n",
    "(SELECT language from UNNEST(pubs.claims_localized) LIMIT 1) = 'en'\n",
    "\"\"\"\n",
    "df_training_set_finished = pd.read_gbq(query, project_id=PROJECT_ID, dialect='standard')\n",
    "#check to make sure we got back a dataset that looks right.\n",
    "print(\"Shape:\", df_training_set_finished.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that the data is prepared, get ready to do the ML training.\n",
    "features, labels = shuffle( df_training_set_finished['text'].values, df_training_set_finished['Label'])\n",
    "\n",
    "#Grid sweep parameters to use the SGDClassifier\n",
    "#there are lots of options on algorithm and parameters to try.  These are some that have worked the best\n",
    "#for me in the past on similar data.\n",
    "parameters = {\n",
    "    'loss': ['log'],\n",
    "    'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "    'n_iter':[3, 8, 12],\n",
    "    'alpha': [0.001, 0.01, 0.1 ],\n",
    "    'learning_rate': ['constant','optimal','invscaling'],\n",
    "    'eta0':[.5,1],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "#Grid search will find the best combination of parameters to use in our ML model\n",
    "grid_search = GridSearchCV(SGDClassifier(), parameters )\n",
    "\n",
    "#Stick a CountVectorizer, which will convert the text into word counts in the pipeline\n",
    "#Next, use a TF-IDF transformer to convert the word counts to TFIDF\n",
    "#Last, do the grid search.\n",
    "#store this all in a pipeline so we can do it over and over.\n",
    "text_clf = Pipeline( [('vect', CountVectorizer(stop_words='english')),\n",
    "     ('tfidf',TfidfTransformer()),\n",
    "     ('clf',grid_search)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search the grid for the best trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Searching\n",
      "Best Score 0.932788374205\n",
      "Best parameters set:\n",
      "\talpha: 0.001\n",
      "\tclass_weight: None\n",
      "\teta0: 1\n",
      "\tlearning_rate: 'constant'\n",
      "\tloss: 'log'\n",
      "\tn_iter: 12\n",
      "\tpenalty: 'none'\n"
     ]
    }
   ],
   "source": [
    "#Fit the data\n",
    "print(\"Grid Searching\")\n",
    "text_clf.fit( features, labels)\n",
    "print(\"Best Score\", grid_search.best_score_)\n",
    "print( \"Best parameters set:\" )\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print (\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best model and do cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.906735751295\n"
     ]
    }
   ],
   "source": [
    "#grab the best estimator from the grid search\n",
    "estimator = grid_search.best_estimator_\n",
    "#create a reuseable pipepline to do the predictions\n",
    "final_pipeline = Pipeline( [('vect', CountVectorizer(stop_words='english')),\n",
    "     ('tfidf',TfidfTransformer()),\n",
    "     ('estimator', estimator)])\n",
    "\n",
    "# split data 65%-35% into training set and test set\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(df_training_set_finished['text'].values,\n",
    "                                                                            df_training_set_finished['Label'].values, test_size=0.35)\n",
    "final_pipeline.fit( features_train, labels_train )\n",
    "\n",
    "accuracy = final_pipeline.score(features_test, labels_test)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "#uncomment here to do a cross val score instead of the test/train split above\n",
    "#score = cross_val_score( final_pipeline, features, labels)\n",
    "#print(\"cross val score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\t\t\t  Pred True \t Pred False\n",
      "BlockChain True: \t 254 \t\t 8\n",
      "BlockChain False: \t 28 \t\t 96\n",
      "False Negatives: 8\n",
      "False Positives: 28\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEUCAYAAAC8piQPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNDNLcSiamaX8H30FogZjwc5QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f11ac9a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "labels_predicted = final_pipeline.predict(features_test)\n",
    "cm = confusion_matrix(labels_test, labels_predicted)\n",
    "\n",
    "#print in text format\n",
    "print(\"Confusion Matrix:\\n\\t\\t\\t\", \" Pred True \\t Pred False\")\n",
    "print\n",
    "print(\"BlockChain True:\",\"\\t\", cm[0][0], \"\\t\\t\", cm[0][1])\n",
    "print(\"BlockChain False:\",\"\\t\", cm[1][0], \"\\t\\t\", cm[1][1])\n",
    "print(\"False Negatives:\", cm[0][1])\n",
    "print(\"False Positives:\", cm[1][0])\n",
    "\n",
    "#now plot confusion matrix with matplotlib to get all fancy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=75)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Greens)\n",
    "plt.colorbar()\n",
    "tick_marks = [0,1]\n",
    "plt.xticks(tick_marks, labels)\n",
    "plt.yticks(tick_marks, labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.text(0, 0, str(cm[0][0]), color='white', fontsize=12, horizontalalignment='center')\n",
    "ax.text(1, 0, str(cm[1][0]), color='black', fontsize=12, horizontalalignment='center')\n",
    "ax.text(0, 1, str(cm[0][1]), color='black', fontsize=12, horizontalalignment='center')\n",
    "ax.text(1, 1, str(cm[1][1]), color='black', fontsize=12, horizontalalignment='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull target porfolio\n",
    "Note: this is a very unsophisticated way to pull the target portfolio.  The best way, in my experience, is to use a third party database that includes all reassignment data.  You can upload patent numbers to GBQ and do a join much as we did on the training data above.  The technique below, however, isn't bad for large portfolios like IBM, Google, and Microsoft, to get an idea before you spend a lot of time making sure you have the correct portfolio to search.  Companies like Intellectual Ventures, which uses many different holding companies, can be notoriously hard to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting query... ok.\n",
      "Job ID: job_D9gakZHCX35BshdCyHhI-Zu_JKcA\n",
      "Query running...\n",
      "Query done.\n",
      "Cache hit.\n",
      "\n",
      "Retrieving results...\n",
      "  Got page: 3; 34% done. Elapsed 7.72 s.\n",
      "  Got page: 4; 45% done. Elapsed 10.42 s.\n",
      "  Got page: 5; 56% done. Elapsed 13.32 s.\n",
      "  Got page: 6; 67% done. Elapsed 16.02 s.\n",
      "  Got page: 7; 78% done. Elapsed 18.23 s.\n",
      "  Got page: 8; 89% done. Elapsed 20.65 s.\n",
      "  Got page: 9; 100% done. Elapsed 23.1 s.\n",
      "Got 8216 rows.\n",
      "\n",
      "Total time taken 23.19 s.\n",
      "Finished at 2018-01-15 16:20:04.\n",
      "(8216, 3)\n"
     ]
    }
   ],
   "source": [
    "#get target portofolio\n",
    "#pull patent applications where the harmonized assignee is Amazon on the face of the patent (might not be current assignee)\n",
    "#The query creates the same text as above, but this time we will use it for prediction instead of training.\n",
    "#this might take a while.  Amazon should have about 8,000 rows, so it will fetch and process quickly.\n",
    "#the query pares the data down by having only patents published after 2000.  If you want a larger dataset, try uncommenting\n",
    "#one of the other assignees bellow.\n",
    "\n",
    "#if you don't want to use Google BigQuery, you can load the results from here:\n",
    "#df_target = pd.read_csv()\n",
    "\n",
    "#assignee = \"IBM%\"\n",
    "#assignee = \"GOOGLE%\"\n",
    "#assignee = \"MICROSOFT%\"\n",
    "assignee = \"AMAZON TECH%\"\n",
    "\n",
    "query = \"\"\"\n",
    "select pubs.publication_number, --pubs.assignee_harmonized,\n",
    "      (SELECT text from UNNEST(pubs.title_localized)) as title,\n",
    "        CONCAT(IFNULL(\n",
    "         (SELECT text from UNNEST(pubs.title_localized)), \" \"), \" \",\n",
    "        IFNULL(\n",
    "         (SELECT text from UNNEST(pubs.abstract_localized)), \" \"), \" \",\n",
    "        IFNULL(  \n",
    "         (SELECT text from UNNEST(pubs.claims_localized)), \" \"), \" \",\n",
    "        IFNULL(\n",
    "         ARRAY_TO_STRING( ARRAY(SELECT code from UNNEST(pubs.cpc)), \" \"), \" \" ), \" \",\n",
    "        IFNULL(\n",
    "         ARRAY_TO_STRING( ARRAY(SELECT REGEXP_REPLACE( code, \"/.*\", \"\") from UNNEST(pubs.cpc)), \" \"), \" \")) as text\n",
    "from\n",
    "  `patents-public-data.patents.publications` as pubs, UNNEST(title_localized) as title\n",
    "where \n",
    "country_code = 'US' and  --US only\n",
    "application_kind = 'A' and --patents only\n",
    "publication_date > 20000000 and  --The patents table uses a very awkward date formulation.  This queries for patents published after Jan 1, 2000.\n",
    "EXISTS( SELECT 1 name from UNNEST(assignee_harmonized) where name LIKE '\"\"\"+ assignee + \"\"\"')\"\"\"\n",
    "\n",
    "df_target = pd.read_gbq(query, project_id=PROJECT_ID, dialect='standard')\n",
    "\n",
    "print(df_target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pipeline and run the predictions.\n",
    "#using predict_proba gives us the probabilty rather than the label. This helps in sorting later.\n",
    "#this might also take a while\n",
    "predictions = final_pipeline.predict_proba(df_target.text.values)\n",
    "\n",
    "#add the predictions to the dataframe\n",
    "# The predictions outcome for our model is tuple of the likelihood of being in category 0 or category 1.\n",
    "#  The list comprehension below splits off just the probability of the row being in Category 1.\n",
    "df_target['BlockChainPredictions'] = [j for i,j in predictions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>title</th>\n",
       "      <th>BlockChainPredictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>US-9311500-B2</td>\n",
       "      <td>Data security using request-supplied keys</td>\n",
       "      <td>0.970489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>US-2016217290-A1</td>\n",
       "      <td>Data security using request-supplied keys</td>\n",
       "      <td>0.968580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>US-8600886-B2</td>\n",
       "      <td>Managing transaction accounts</td>\n",
       "      <td>0.959393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>US-2012136710-A1</td>\n",
       "      <td>Digital Coupon System</td>\n",
       "      <td>0.957294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td>US-2012136707-A1</td>\n",
       "      <td>Digital Coupon System</td>\n",
       "      <td>0.956874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>US-2012136712-A1</td>\n",
       "      <td>Digital Coupon System</td>\n",
       "      <td>0.952514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>US-2013238504-A1</td>\n",
       "      <td>Performing automatically authorized programmatic transactions</td>\n",
       "      <td>0.947606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>US-2015089244-A1</td>\n",
       "      <td>Data security using request-supplied keys</td>\n",
       "      <td>0.945723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>US-2016191241-A1</td>\n",
       "      <td>Distributed public key revocation</td>\n",
       "      <td>0.945159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>US-2017195283-A1</td>\n",
       "      <td>Allocating identifiers with minimal fragmentation</td>\n",
       "      <td>0.937665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532</th>\n",
       "      <td>US-2012136706-A1</td>\n",
       "      <td>Digital Coupon System</td>\n",
       "      <td>0.936986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>US-2017171219-A1</td>\n",
       "      <td>Signed envelope encryption</td>\n",
       "      <td>0.927431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7470</th>\n",
       "      <td>US-9087187-B1</td>\n",
       "      <td>Unique credentials verification</td>\n",
       "      <td>0.924442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>US-9674162-B1</td>\n",
       "      <td>Updating encrypted cryptographic key pair</td>\n",
       "      <td>0.919130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>US-9286608-B1</td>\n",
       "      <td>System and method for predictive payment authorizations</td>\n",
       "      <td>0.916734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6161</th>\n",
       "      <td>US-2016248589-A1</td>\n",
       "      <td>Cryptographically verified repeatable virtualized computing</td>\n",
       "      <td>0.911653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5534</th>\n",
       "      <td>US-7814229-B1</td>\n",
       "      <td>Constraint-based domain name system</td>\n",
       "      <td>0.911245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>US-9699146-B1</td>\n",
       "      <td>Secure access to user data</td>\n",
       "      <td>0.908116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>US-9258120-B1</td>\n",
       "      <td>Distributed public key revocation</td>\n",
       "      <td>0.906655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>US-2017093569-A1</td>\n",
       "      <td>Supporting a fixed transaction rate with a variably-backed logical cryptographic key</td>\n",
       "      <td>0.905095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     publication_number  \\\n",
       "518   US-9311500-B2       \n",
       "5980  US-2016217290-A1    \n",
       "3798  US-8600886-B2       \n",
       "5974  US-2012136710-A1    \n",
       "7828  US-2012136707-A1    \n",
       "2393  US-2012136712-A1    \n",
       "4759  US-2013238504-A1    \n",
       "5570  US-2015089244-A1    \n",
       "1477  US-2016191241-A1    \n",
       "1316  US-2017195283-A1    \n",
       "5532  US-2012136706-A1    \n",
       "525   US-2017171219-A1    \n",
       "7470  US-9087187-B1       \n",
       "4436  US-9674162-B1       \n",
       "5666  US-9286608-B1       \n",
       "6161  US-2016248589-A1    \n",
       "5534  US-7814229-B1       \n",
       "4508  US-9699146-B1       \n",
       "305   US-9258120-B1       \n",
       "4532  US-2017093569-A1    \n",
       "\n",
       "                                                                                     title  \\\n",
       "518   Data security using request-supplied keys                                              \n",
       "5980  Data security using request-supplied keys                                              \n",
       "3798  Managing transaction accounts                                                          \n",
       "5974  Digital Coupon System                                                                  \n",
       "7828  Digital Coupon System                                                                  \n",
       "2393  Digital Coupon System                                                                  \n",
       "4759  Performing automatically authorized programmatic transactions                          \n",
       "5570  Data security using request-supplied keys                                              \n",
       "1477  Distributed public key revocation                                                      \n",
       "1316  Allocating identifiers with minimal fragmentation                                      \n",
       "5532  Digital Coupon System                                                                  \n",
       "525   Signed envelope encryption                                                             \n",
       "7470  Unique credentials verification                                                        \n",
       "4436  Updating encrypted cryptographic key pair                                              \n",
       "5666  System and method for predictive payment authorizations                                \n",
       "6161  Cryptographically verified repeatable virtualized computing                            \n",
       "5534  Constraint-based domain name system                                                    \n",
       "4508  Secure access to user data                                                             \n",
       "305   Distributed public key revocation                                                      \n",
       "4532  Supporting a fixed transaction rate with a variably-backed logical cryptographic key   \n",
       "\n",
       "      BlockChainPredictions  \n",
       "518   0.970489               \n",
       "5980  0.968580               \n",
       "3798  0.959393               \n",
       "5974  0.957294               \n",
       "7828  0.956874               \n",
       "2393  0.952514               \n",
       "4759  0.947606               \n",
       "5570  0.945723               \n",
       "1477  0.945159               \n",
       "1316  0.937665               \n",
       "5532  0.936986               \n",
       "525   0.927431               \n",
       "7470  0.924442               \n",
       "4436  0.919130               \n",
       "5666  0.916734               \n",
       "6161  0.911653               \n",
       "5534  0.911245               \n",
       "4508  0.908116               \n",
       "305   0.906655               \n",
       "4532  0.905095               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets look at the top 20 patents IBM owns that might be relevant to BlockChain:\n",
    "df_display = df_target.nlargest(20, 'BlockChainPredictions').sort_values('BlockChainPredictions', ascending=False)\n",
    "#Why do nlargest and then sort, as opposed to doing sort and slicing?  Because n-largest only requires one\n",
    "#pass through the data, then sorting 20 items is trivial.  Sorting all ~200k patents is wasteful when we only want the top 20.\n",
    "\n",
    "#make columns wrap instead of truncate:\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "#drop the text column on display so it doesn't clutter everything, then display\n",
    "display(df_display.drop(\"text\", axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The results are interesting.  If you are looking at the Amazon results, you can see there are some patent titles that look highly related in the top 20, and some that look way off.  From here, the magic is improving your training data by adding positive and negative examples.  Additionally, \"Block Chain\" may be too broad of a topic.  Do you want applications of block chain, or the underlying mechanism that drives block chain?  Are you looking for the component parts of Block Chain like cryptographic functions, or are you only interested in patents that are refinements to the overall Block Chain system?\n",
    "\n",
    "This is a bit of a toy example to let people get started actually doing data science experiments on real patent data.  This tutorial is aimed at the relative beginner to machine learning.\n",
    "\n",
    "I hope you have learned something by reading this walk through.  Find me on LinkedIn at https://www.linkedin.com/in/davidandrewsjd/.  \n",
    "\n",
    "David Andrews\n",
    "Founder\n",
    "Legal Analytics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
