{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patent Analysis in Python\n",
    "### Sample using a training dataset directed at BlockChain patents and predicting relevance in the IBM portofolio\n",
    "David Andrews\n",
    "Legal Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample connects to Google BigQuery to retrieve patent data.  You need to do some setup in Google's cloud dev platform if you are not already using Google BigQuery.  You can reference one of the many great tutorials on setting up Google BigQuery for the first time to get the libraries installed, credentials cached, and project ID setup.\n",
    "\n",
    "#### Caveat\n",
    "This sample uses a very dumb training set.  The 'positive' samples, or samples labeled as being related to Block Chain, were gathered by doing a simple keyword search on Google Patents.  The results were not reviewed by hand and there was no effort to be inclusive.  As a result, the final results are interesting, but not demonstrative of what a fully-trained ML model can do when predicting results.  The 'negative' samples were created by doing a random search for patents, which means they are probably not blockchain related.  Immediately better results could be obtained by providing negative samples that weed out things like financial transactions patents that don't use block chain or similar technology. If you improve the training set and I would appreciate the opportunity to improve these results by including your updated training data.  You can email me at david@analytics.legal and I can re-publish the training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#import lots of stuff\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication_Number</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-2015310424-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US-2015120567-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US-2015170112-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US-2015379510-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US-2015287026-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US-2015356555-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US-2015332256-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>US-2015371224-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US-2015332283-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>US-2015206106-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>US-2015356524-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US-2016321654-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>US-2017011460-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>US-9397985-B1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>US-2016261411-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>US-2015294308-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>US-2015324764-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>US-2016342977-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>US-2016300234-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>US-2017177855-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>US-9298806-B1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>US-2017178237-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>US-2016012424-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>US-2015244690-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>US-2017046651-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>US-2017132630-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>US-2015278820-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>US-2016218879-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>US-2015227890-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>US-2016350749-A1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>US-6052674-A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>US-6334116-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>US-6078907-A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>US-6108644-A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>US-6081790-A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>US-7567934-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>US-2003097331-A1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>US-6450407-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>US-6173272-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>US-2003004827-A1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>US-6076074-A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>US-2005197957-A1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>US-7349557-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>WO-1999066436-A1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>US-6418420-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>US-6606602-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>US-6601761-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>US-6119108-A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>US-7509286-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>US-7933821-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>US-8019667-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>US-7519551-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>US-7536350-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>US-7236950-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>US-7127606-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>US-6339766-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>US-6532450-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>US-6577861-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>US-6512919-B2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>US-7209889-B1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Publication_Number  Label\n",
       "0      US-2015310424-A1      1\n",
       "1      US-2015120567-A1      1\n",
       "2      US-2015170112-A1      1\n",
       "3      US-2015379510-A1      1\n",
       "4      US-2015287026-A1      1\n",
       "5      US-2015356555-A1      1\n",
       "6      US-2015332256-A1      1\n",
       "7      US-2015371224-A1      1\n",
       "8      US-2015332283-A1      1\n",
       "9      US-2015206106-A1      1\n",
       "10     US-2015356524-A1      1\n",
       "11     US-2016321654-A1      1\n",
       "12     US-2017011460-A1      1\n",
       "13        US-9397985-B1      1\n",
       "14     US-2016261411-A1      1\n",
       "15     US-2015294308-A1      1\n",
       "16     US-2015324764-A1      1\n",
       "17     US-2016342977-A1      1\n",
       "18     US-2016300234-A1      1\n",
       "19     US-2017177855-A1      1\n",
       "20        US-9298806-B1      1\n",
       "21     US-2017178237-A1      1\n",
       "22     US-2016012424-A1      1\n",
       "23     US-2015244690-A1      1\n",
       "24     US-2017046651-A1      1\n",
       "25     US-2017132630-A1      1\n",
       "26     US-2015278820-A1      1\n",
       "27     US-2016218879-A1      1\n",
       "28     US-2015227890-A1      1\n",
       "29     US-2016350749-A1      1\n",
       "...                 ...    ...\n",
       "1126       US-6052674-A      0\n",
       "1127      US-6334116-B1      0\n",
       "1128       US-6078907-A      0\n",
       "1129       US-6108644-A      0\n",
       "1130       US-6081790-A      0\n",
       "1131      US-7567934-B2      0\n",
       "1132   US-2003097331-A1      0\n",
       "1133      US-6450407-B1      0\n",
       "1134      US-6173272-B1      0\n",
       "1135   US-2003004827-A1      0\n",
       "1136       US-6076074-A      0\n",
       "1137   US-2005197957-A1      0\n",
       "1138      US-7349557-B2      0\n",
       "1139   WO-1999066436-A1      0\n",
       "1140      US-6418420-B1      0\n",
       "1141      US-6606602-B1      0\n",
       "1142      US-6601761-B1      0\n",
       "1143       US-6119108-A      0\n",
       "1144      US-7509286-B1      0\n",
       "1145      US-7933821-B1      0\n",
       "1146      US-8019667-B1      0\n",
       "1147      US-7519551-B2      0\n",
       "1148      US-7536350-B1      0\n",
       "1149      US-7236950-B2      0\n",
       "1150      US-7127606-B2      0\n",
       "1151      US-6339766-B1      0\n",
       "1152      US-6532450-B1      0\n",
       "1153      US-6577861-B2      0\n",
       "1154      US-6512919-B2      0\n",
       "1155      US-7209889-B1      0\n",
       "\n",
       "[1154 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load in the samples of patents we want to find\n",
    "#these files are just flat lists of patent numbers.  Positives are examples of block chain patents and negatives \n",
    "#are random non-blockchain patents.  Stored on public google sheets share.\n",
    "negative_url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vQ8MuAkmbFD6XeAjPTIP33pNU17QI09MWgFIx8lkYcoQoc_NcxPD7SefxOglwknU_R9mtu5BEd1hrmA/pub?output=csv\"\n",
    "positive_url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSD-tiMAUTosTzEz9jiqK0JMhFLr3s_Jeb7J5Ry39NoIaEHE-Iqr1M7etvDJBTZA0ilgmUjb6KU-TCs/pub?output=csv\"\n",
    "df_positive_samples = pd.read_csv(positive_url)\n",
    "#load samples of patents that are counter-examples\n",
    "df_negative_samples = pd.read_csv(negative_url)\n",
    "\n",
    "#Create Label column to hold the labels\n",
    "#label blockchain patents 1\n",
    "df_positive_samples['Label'] = 1\n",
    "#label non-blockahin patents 0\n",
    "df_negative_samples['Label'] = 0\n",
    "\n",
    "#combine labeled data into a training set\n",
    "df_training_set = pd.concat([df_positive_samples, df_negative_samples], ignore_index=True)\n",
    "\n",
    "#change the format of the publication number from US1234567B2 to US-1234567-B2 to match the format in the database\n",
    "df_training_set['Publication_Number'] = df_training_set['Publication_Number'].str.replace(r\"(\\D*)(\\d*)(\\D\\d?)\", \"\\\\1-\\\\2-\\\\3\")\n",
    "#input data has some funky pub numbers for applications with an extra 0 after the year portion of the pub number.\n",
    "#need to strip it so it matches the format in Google BigQuery\n",
    "df_training_set['Publication_Number'] = df_training_set['Publication_Number'].str.replace(r\"(\\D*-)(\\d{4})0(\\d{6})(-A1)\",\n",
    "                                                                                         \"\\\\1\\\\2\\\\3\\\\4\")\n",
    "\n",
    "#unpacking the above REGEXP a little:\n",
    "# (\\D*) = grab all the non-digits at the front e.g. US\n",
    "# (\\d*) = grab all the digits, e.g. 1234567\n",
    "# (\\D\\d?) = grab a trailing non-digit optionally followed by a digit e.g. A1 or B2 or A \n",
    "\n",
    "\n",
    "df_training_set.drop_duplicates(['Publication_Number'], inplace=True)\n",
    "#show the training set to see what it looks like.  Make sure it imported correctly.\n",
    "display(df_training_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note there are some non-US patents in the Negatives training example.  Our SQL join below will weed those out, so you may notice that the row count decreases from this query to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to  Google BigQuery and upload patent numbers & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Streaming Insert is 100.0% Complete\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load the dataset to Google BigQuery so we can join against the public patents data\n",
    "\n",
    "#If you don't want to try to get GBQ working, you can download the results of this step here:\n",
    "#combined_url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSfXq_QpXjL3eskKnbezF33GgcBM7O1KB-TAPrfcZk1cYXdQWQWU5X_oAICJr5ipXearXbJ19_Rp4PY/pub?output=csv\"\n",
    "#df_training_set_finished = pd.read_csv(\"combined_url\")\n",
    "#then skip to Prepare Machine Learning Pipeline below\n",
    "\n",
    "\n",
    "# Variables to be used to access GBQ, replace with your project id, and optionally change the table and\n",
    "# and dataset name.\n",
    "PROJECT_ID = 'My_project_id_goes_here'\n",
    "DEST_DATASET = 'my_new_dataset'\n",
    "samples_table = 'temp'\n",
    "\n",
    "# Create a python client we can use for executing table creation queries\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "# Create an HTTP client for additional functionality.\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "http_client = discovery.build('bigquery', 'v2', credentials=credentials)\n",
    "\n",
    "#attach to the dataset\n",
    "dataset = client.dataset(DEST_DATASET)\n",
    "\n",
    "#create the table by having Pandas push up the dataframe as a table\n",
    "full_table_path = '{}.{}'.format(DEST_DATASET, samples_table)\n",
    "df_training_set.to_gbq(destination_table=full_table_path,\n",
    "          project_id=PROJECT_ID,\n",
    "          if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query BigQuery to get training text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting query... ok.\n",
      "Job ID: job_u2uDVXzTh_SgLsACIsao5OIJXhfp\n",
      "Query running...\n",
      "Query done.\n",
      "Processed: 155.0 GB\n",
      "Standard price: $0.76 USD\n",
      "\n",
      "Retrieving results...\n",
      "Got 1101 rows.\n",
      "\n",
      "Total time taken 6.12 s.\n",
      "Finished at 2018-01-15 15:33:26.\n",
      "Shape: (1101, 3)\n"
     ]
    }
   ],
   "source": [
    "#create our query string.  The query joins the BigQuery patent data using our training set\n",
    "# publication number.  Because we formatted in Python to match the BigQuery format, we can just use traing equality\n",
    "# in the \"on\" clause of the join.\n",
    "# The concat combines the data fields we are interested in.  For our training data, we are going to use\n",
    "# the title, abstract, claims, and CPC codes combined into one text block to feed into the machine learning code.\n",
    "\n",
    "query = \"\"\"\n",
    "select pubs.publication_number, Label,\n",
    "  CONCAT(\n",
    "    IFNULL(\n",
    "     (SELECT text from UNNEST(pubs.title_localized)), \" \"), \" \",\n",
    "    IFNULL(\n",
    "     (SELECT text from UNNEST(pubs.abstract_localized)), \" \"), \" \",\n",
    "    IFNULL(  \n",
    "     (SELECT text from UNNEST(pubs.claims_localized)), \" \"), \" \",\n",
    "    IFNULL(\n",
    "     ARRAY_TO_STRING( ARRAY(SELECT code from UNNEST(pubs.cpc)), \" \"), \" \" ), \" \",\n",
    "    IFNULL(\n",
    "     ARRAY_TO_STRING( ARRAY(SELECT REGEXP_REPLACE( code, \"/.*\", \"\") from UNNEST(pubs.cpc)), \" \"), \" \")) as text\n",
    "from\n",
    "  `patents-public-data.patents.publications` as pubs, UNNEST(title_localized) as title\n",
    "  JOIN `\"\"\" + full_table_path + \"\"\"` as input\n",
    "  on pubs.publication_number = input.Publication_Number  \n",
    "where (SELECT language from UNNEST(pubs.title_localized) LIMIT 1) = 'en' and\n",
    "(SELECT language from UNNEST(pubs.abstract_localized) LIMIT 1) = 'en' and\n",
    "(SELECT language from UNNEST(pubs.claims_localized) LIMIT 1) = 'en'\n",
    "\"\"\"\n",
    "df_training_set_finished = pd.read_gbq(query, project_id=PROJECT_ID, dialect='standard')\n",
    "#check to make sure we got back a dataset that looks right.\n",
    "print(\"Shape:\", df_training_set_finished.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that the data is prepared, get ready to do the ML training.\n",
    "features, labels = shuffle( df_training_set_finished['text'].values, df_training_set_finished['Label'])\n",
    "\n",
    "#Grid sweep parameters to use the SGDClassifier\n",
    "#there are lots of options on algorithm and parameters to try.  These are some that have worked the best\n",
    "#for me in the past on similar data.\n",
    "parameters = {\n",
    "    'loss': ['log'],\n",
    "    'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "    'n_iter':[3, 8, 12],\n",
    "    'alpha': [0.001, 0.01, 0.1 ],\n",
    "    'learning_rate': ['constant','optimal','invscaling'],\n",
    "    'eta0':[.5,1],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "#Grid search will find the best combination of parameters to use in our ML model\n",
    "grid_search = GridSearchCV(SGDClassifier(), parameters )\n",
    "\n",
    "#Stick a CountVectorizer, which will convert the text into word counts in the pipeline\n",
    "#Next, use a TF-IDF transformer to convert the word counts to TFIDF\n",
    "#Last, do the grid search.\n",
    "#store this all in a pipeline so we can do it over and over.\n",
    "text_clf = Pipeline( [('vect', CountVectorizer(stop_words='english')),\n",
    "     ('tfidf',TfidfTransformer()),\n",
    "     ('clf',grid_search)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search the grid for the best trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Searching\n",
      "Best Score 0.933696639419\n",
      "Best parameters set:\n",
      "\talpha: 0.01\n",
      "\tclass_weight: 'balanced'\n",
      "\teta0: 1\n",
      "\tlearning_rate: 'constant'\n",
      "\tloss: 'log'\n",
      "\tn_iter: 8\n",
      "\tpenalty: 'none'\n"
     ]
    }
   ],
   "source": [
    "#Fit the data\n",
    "print(\"Grid Searching\")\n",
    "text_clf.fit( features, labels)\n",
    "print(\"Best Score\", grid_search.best_score_)\n",
    "print( \"Best parameters set:\" )\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print (\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best model and do cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
      "Accuracy:  0.943005181347\n"
     ]
    }
   ],
   "source": [
    "#grab the best estimator from the grid search\n",
    "estimator = grid_search.best_estimator_\n",
    "#create a reuseable pipepline to do the predictions\n",
    "final_pipeline = Pipeline( [('vect', CountVectorizer(stop_words='english')),\n",
    "     ('tfidf',TfidfTransformer()),\n",
    "     ('estimator', estimator)])\n",
    "\n",
    "# split data 65%-35% into training set and test set\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(df_training_set_finished['text'].values,\n",
    "                                                                            df_training_set_finished['Label'].values, test_size=0.35)\n",
    "final_pipeline.fit( features_train, labels_train )\n",
    "\n",
    "accuracy = final_pipeline.score(features_test, labels_test)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "#uncomment here to do a cross val score instead of the test/train split above\n",
    "#score = cross_val_score( final_pipeline, features, labels)\n",
    "#print(\"cross val score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\t\t\t  Pred True \t Pred False\n",
      "BlockChain True: \t 264 \t\t 6\n",
      "BlockChain False: \t 16 \t\t 100\n",
      "False Negatives: 6\n",
      "False Positives: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEUCAYAAAC8piQPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNDNL+f96hoEYAGy6kwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ecf53a6208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "labels_predicted = final_pipeline.predict(features_test)\n",
    "cm = confusion_matrix(labels_test, labels_predicted)\n",
    "\n",
    "#print in text format\n",
    "print(\"Confusion Matrix:\\n\\t\\t\\t\", \" Pred True \\t Pred False\")\n",
    "print\n",
    "print(\"BlockChain True:\",\"\\t\", cm[0][0], \"\\t\\t\", cm[0][1])\n",
    "print(\"BlockChain False:\",\"\\t\", cm[1][0], \"\\t\\t\", cm[1][1])\n",
    "print(\"False Negatives:\", cm[0][1])\n",
    "print(\"False Positives:\", cm[1][0])\n",
    "\n",
    "#now plot confusion matrix with matplotlib to get all fancy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=75)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Greens)\n",
    "plt.colorbar()\n",
    "tick_marks = [0,1]\n",
    "plt.xticks(tick_marks, labels)\n",
    "plt.yticks(tick_marks, labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.text(0, 0, str(cm[0][0]), color='white', fontsize=12, horizontalalignment='center')\n",
    "ax.text(1, 0, str(cm[1][0]), color='black', fontsize=12, horizontalalignment='center')\n",
    "ax.text(0, 1, str(cm[0][1]), color='black', fontsize=12, horizontalalignment='center')\n",
    "ax.text(1, 1, str(cm[1][1]), color='black', fontsize=12, horizontalalignment='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull target porfolio\n",
    "Note: this is a very unsophisticated way to pull the target portfolio.  The best way, in my experience, is to use a third party database that includes all reassignment data.  You can upload patent numbers to GBQ and do a join much as we did on the training data above.  The technique below, however, isn't bad for large portfolios like IBM, Google, and Microsoft, to get an idea before you spend a lot of time making sure you have the correct portfolio to search.  Companies like Intellectual Ventures, which uses many different holding companies, can be notoriously hard to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting query... ok.\n",
      "Job ID: job_TWDD6fuHoUBGyyRRf_ysvwkidOQU\n",
      "Query running...\n",
      "Query done.\n",
      "Cache hit.\n",
      "\n",
      "Retrieving results...\n",
      "  Got page: 3; 34% done. Elapsed 7.52 s.\n",
      "  Got page: 4; 45% done. Elapsed 9.98 s.\n",
      "  Got page: 5; 56% done. Elapsed 12.59 s.\n",
      "  Got page: 6; 67% done. Elapsed 14.9 s.\n",
      "  Got page: 7; 78% done. Elapsed 17.59 s.\n",
      "  Got page: 8; 89% done. Elapsed 20.07 s.\n",
      "  Got page: 9; 100% done. Elapsed 22.29 s.\n",
      "Got 8216 rows.\n",
      "\n",
      "Total time taken 22.4 s.\n",
      "Finished at 2018-01-15 15:34:15.\n",
      "(8216, 3)\n"
     ]
    }
   ],
   "source": [
    "#get target portofolio\n",
    "#pull patent applications where the harmonized assignee is Amazon on the face of the patent (might not be current assignee)\n",
    "#The query creates the same text as above, but this time we will use it for prediction instead of training.\n",
    "#this might take a while.  Amazon should have about 8,000 rows, so it will fetch and process quickly.\n",
    "#the query pares the data down by having only patents published after 2000.  If you want a larger dataset, try uncommenting\n",
    "#one of the other assignees bellow.\n",
    "\n",
    "#if you don't want to use Google BigQuery, you can load the results from here:\n",
    "#df_target = pd.read_csv()\n",
    "\n",
    "#assignee = \"IBM%\"\n",
    "#assignee = \"GOOGLE%\"\n",
    "#assignee = \"MICROSOFT%\"\n",
    "assignee = \"AMAZON TECH%\"\n",
    "\n",
    "query = \"\"\"\n",
    "select pubs.publication_number, --pubs.assignee_harmonized,\n",
    "      (SELECT text from UNNEST(pubs.title_localized)) as title,\n",
    "        CONCAT(IFNULL(\n",
    "         (SELECT text from UNNEST(pubs.title_localized)), \" \"), \" \",\n",
    "        IFNULL(\n",
    "         (SELECT text from UNNEST(pubs.abstract_localized)), \" \"), \" \",\n",
    "        IFNULL(  \n",
    "         (SELECT text from UNNEST(pubs.claims_localized)), \" \"), \" \",\n",
    "        IFNULL(\n",
    "         ARRAY_TO_STRING( ARRAY(SELECT code from UNNEST(pubs.cpc)), \" \"), \" \" ), \" \",\n",
    "        IFNULL(\n",
    "         ARRAY_TO_STRING( ARRAY(SELECT REGEXP_REPLACE( code, \"/.*\", \"\") from UNNEST(pubs.cpc)), \" \"), \" \")) as text\n",
    "from\n",
    "  `patents-public-data.patents.publications` as pubs, UNNEST(title_localized) as title\n",
    "where \n",
    "country_code = 'US' and  --US only\n",
    "application_kind = 'A' and --patents only\n",
    "publication_date > 20000000 and  --The patents table uses a very awkward date formulation.  This queries for patents published after Jan 1, 2000.\n",
    "EXISTS( SELECT 1 name from UNNEST(assignee_harmonized) where name LIKE '\"\"\"+ assignee + \"\"\"')\"\"\"\n",
    "\n",
    "df_target = pd.read_gbq(query, project_id=PROJECT_ID, dialect='standard')\n",
    "\n",
    "print(df_target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pipeline and run the predictions.\n",
    "#using predict_proba gives us the probabilty rather than the label. This helps in sorting later.\n",
    "#this might also take a while\n",
    "predictions = final_pipeline.predict_proba(df_target.text.values)\n",
    "\n",
    "#add the predictions to the dataframe\n",
    "# The predictions outcome for our model is tuple of the likelihood of being in category 0 or category 1.\n",
    "#  The list comprehension below splits off just the probability of the row being in Category 1.\n",
    "df_target['BlockChainPredictions'] = [j for i,j in predictions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>title</th>\n",
       "      <th>BlockChainPredictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>US-2016217290-A1</td>\n",
       "      <td>Data security using request-supplied keys</td>\n",
       "      <td>0.976326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>US-9053479-B1</td>\n",
       "      <td>Method and system for product restocking using machine-readable codes</td>\n",
       "      <td>0.974511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>US-9311500-B2</td>\n",
       "      <td>Data security using request-supplied keys</td>\n",
       "      <td>0.973095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>US-2017171219-A1</td>\n",
       "      <td>Signed envelope encryption</td>\n",
       "      <td>0.969608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>US-9286608-B1</td>\n",
       "      <td>System and method for predictive payment authorizations</td>\n",
       "      <td>0.965634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>US-2015089244-A1</td>\n",
       "      <td>Data security using request-supplied keys</td>\n",
       "      <td>0.963617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>US-2017093569-A1</td>\n",
       "      <td>Supporting a fixed transaction rate with a variably-backed logical cryptographic key</td>\n",
       "      <td>0.954808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>US-2013238504-A1</td>\n",
       "      <td>Performing automatically authorized programmatic transactions</td>\n",
       "      <td>0.952902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>US-2017195283-A1</td>\n",
       "      <td>Allocating identifiers with minimal fragmentation</td>\n",
       "      <td>0.951087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4349</th>\n",
       "      <td>US-9172532-B1</td>\n",
       "      <td>Multi-tiered encryption system for efficiently regulating use of encryption keys</td>\n",
       "      <td>0.950827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>US-2017006018-A1</td>\n",
       "      <td>Key export techniques</td>\n",
       "      <td>0.942674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>US-2016021118-A1</td>\n",
       "      <td>Parameter based key derivation</td>\n",
       "      <td>0.939419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>US-9674162-B1</td>\n",
       "      <td>Updating encrypted cryptographic key pair</td>\n",
       "      <td>0.937933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6677</th>\n",
       "      <td>US-7747475-B1</td>\n",
       "      <td>Intelligent and firm currency conversion</td>\n",
       "      <td>0.937668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7168</th>\n",
       "      <td>US-2016344549-A1</td>\n",
       "      <td>Secure initialization vector generation</td>\n",
       "      <td>0.937157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>US-9699146-B1</td>\n",
       "      <td>Secure access to user data</td>\n",
       "      <td>0.936768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4659</th>\n",
       "      <td>US-8655786-B2</td>\n",
       "      <td>Aggregate constraints for payment transactions</td>\n",
       "      <td>0.930266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>US-8600886-B2</td>\n",
       "      <td>Managing transaction accounts</td>\n",
       "      <td>0.925877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>US-9722974-B1</td>\n",
       "      <td>Automated data re-encryption process in multi-tiered encryption system</td>\n",
       "      <td>0.922903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>US-9407440-B2</td>\n",
       "      <td>Multiple authority data security and access</td>\n",
       "      <td>0.922329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     publication_number  \\\n",
       "5980  US-2016217290-A1    \n",
       "7945  US-9053479-B1       \n",
       "518   US-9311500-B2       \n",
       "525   US-2017171219-A1    \n",
       "5666  US-9286608-B1       \n",
       "5570  US-2015089244-A1    \n",
       "4532  US-2017093569-A1    \n",
       "4759  US-2013238504-A1    \n",
       "1316  US-2017195283-A1    \n",
       "4349  US-9172532-B1       \n",
       "6611  US-2017006018-A1    \n",
       "5911  US-2016021118-A1    \n",
       "4436  US-9674162-B1       \n",
       "6677  US-7747475-B1       \n",
       "7168  US-2016344549-A1    \n",
       "4508  US-9699146-B1       \n",
       "4659  US-8655786-B2       \n",
       "3798  US-8600886-B2       \n",
       "1369  US-9722974-B1       \n",
       "582   US-9407440-B2       \n",
       "\n",
       "                                                                                     title  \\\n",
       "5980  Data security using request-supplied keys                                              \n",
       "7945  Method and system for product restocking using machine-readable codes                  \n",
       "518   Data security using request-supplied keys                                              \n",
       "525   Signed envelope encryption                                                             \n",
       "5666  System and method for predictive payment authorizations                                \n",
       "5570  Data security using request-supplied keys                                              \n",
       "4532  Supporting a fixed transaction rate with a variably-backed logical cryptographic key   \n",
       "4759  Performing automatically authorized programmatic transactions                          \n",
       "1316  Allocating identifiers with minimal fragmentation                                      \n",
       "4349  Multi-tiered encryption system for efficiently regulating use of encryption keys       \n",
       "6611  Key export techniques                                                                  \n",
       "5911  Parameter based key derivation                                                         \n",
       "4436  Updating encrypted cryptographic key pair                                              \n",
       "6677  Intelligent and firm currency conversion                                               \n",
       "7168  Secure initialization vector generation                                                \n",
       "4508  Secure access to user data                                                             \n",
       "4659  Aggregate constraints for payment transactions                                         \n",
       "3798  Managing transaction accounts                                                          \n",
       "1369  Automated data re-encryption process in multi-tiered encryption system                 \n",
       "582   Multiple authority data security and access                                            \n",
       "\n",
       "      BlockChainPredictions  \n",
       "5980  0.976326               \n",
       "7945  0.974511               \n",
       "518   0.973095               \n",
       "525   0.969608               \n",
       "5666  0.965634               \n",
       "5570  0.963617               \n",
       "4532  0.954808               \n",
       "4759  0.952902               \n",
       "1316  0.951087               \n",
       "4349  0.950827               \n",
       "6611  0.942674               \n",
       "5911  0.939419               \n",
       "4436  0.937933               \n",
       "6677  0.937668               \n",
       "7168  0.937157               \n",
       "4508  0.936768               \n",
       "4659  0.930266               \n",
       "3798  0.925877               \n",
       "1369  0.922903               \n",
       "582   0.922329               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets look at the top 20 patents IBM owns that might be relevant to BlockChain:\n",
    "df_display = df_target.nlargest(20, 'BlockChainPredictions').sort_values('BlockChainPredictions', ascending=False)\n",
    "#Why do nlargest and then sort, as opposed to doing sort and slicing?  Because n-largest only requires one\n",
    "#pass through the data, then sorting 20 items is trivial.  Sorting all ~200k patents is wasteful when we only want the top 20.\n",
    "\n",
    "#make columns wrap instead of truncate:\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "#drop the text column on display so it doesn't clutter everything, then display\n",
    "display(df_display.drop(\"text\", axis=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
